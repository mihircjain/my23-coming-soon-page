# ðŸš€ Production Deployment Guide

## Overview
Your **MY23 Running Coach** system is now production-ready with:
- **Frontend**: React/Vite app deployed to Vercel
- **MCP Server**: Deployed to Render at `https://strava-mcp-server.onrender.com` âœ…
- **AI Chat API**: Serverless functions on Vercel with Gemini integration

## ðŸŽ¯ Architecture

```
Frontend (Vercel)
    â†“
Vercel API Routes (/api/*)
    â†“
MCP Server (Render) â†’ Strava API  ðŸŽ¯ CORRECT
    â†“
Gemini AI (Google) for intelligent responses
```

## ðŸ”§ Environment Variables Setup

### 1. **Create `.env.local` for Development**
```bash
# Strava API
STRAVA_ACCESS_TOKEN=d74aa70fd9b59d8921fad453aefd82848899bb1d
VITE_STRAVA_ACCESS_TOKEN=d74aa70fd9b59d8921fad453aefd82848899bb1d

# MCP Server (Production Render URL) ðŸŽ¯ RENDER
MCP_SERVER_URL=https://strava-mcp-server.onrender.com
NEXT_PUBLIC_MCP_API_URL=https://strava-mcp-server.onrender.com

# Google Gemini AI
GEMINI_API_KEY=AIzaSyCcypHkXBvRUBWYNbmpq2GnIOa4tvhUlhc

# Firebase (Optional)
VITE_FIREBASE_API_KEY=your_firebase_api_key
VITE_FIREBASE_PROJECT_ID=your_firebase_project_id
VITE_FIREBASE_AUTH_DOMAIN=your_project_id.firebaseapp.com
VITE_FIREBASE_STORAGE_BUCKET=your_project_id.appspot.com
VITE_FIREBASE_MESSAGING_SENDER_ID=your_sender_id
VITE_FIREBASE_APP_ID=your_app_id
```

### 2. **Render MCP Server Environment Variables** âœ… 
Go to your **Render dashboard** for the MCP server and ensure:
```bash
STRAVA_ACCESS_TOKEN=d74aa70fd9b59d8921fad453aefd82848899bb1d
# Add any other required environment variables for your MCP server
```

### 3. **Vercel Environment Variables** 
In your **Vercel dashboard**, add:
```bash
# Strava API
STRAVA_ACCESS_TOKEN=d74aa70fd9b59d8921fad453aefd82848899bb1d

# MCP Server (Your Render URL)
MCP_SERVER_URL=https://strava-mcp-server.onrender.com

# Gemini AI
GEMINI_API_KEY=AIzaSyCcypHkXBvRUBWYNbmpq2GnIOa4tvhUlhc

# Firebase (if using)
FIREBASE_PROJECT_ID=your_project_id
FIREBASE_CLIENT_EMAIL=your_service_account_email  
FIREBASE_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\nyour_private_key\n-----END PRIVATE KEY-----"
```

## ðŸš€ Deployment Steps

### 1. **Deploy to Vercel**
```bash
# Build the project
npm run build

# Deploy to Vercel
vercel --prod

# Or connect GitHub repo for auto-deployment
```

### 2. **Test Production URLs**
- **Frontend**: https://your-app.vercel.app/mcp-coach
- **MCP API**: https://strava-mcp-server.onrender.com/health
- **Chat API**: https://your-app.vercel.app/api/chat-mcp-intelligent

## âœ… Production Checklist

- [x] **MCP Server**: Deployed on Render with environment variables
- [x] **Frontend**: Ready for Vercel deployment  
- [x] **API Routes**: Updated to use production Render MCP URL
- [x] **Environment Variables**: Configured for production
- [x] **Heart Rate Data**: Working with separate HR requests
- [x] **Vercel Configuration**: Fixed runtime version

## ðŸ”§ Key Production Changes Made

1. **Updated all API routes** to use `https://strava-mcp-server.onrender.com`
2. **Fixed Vercel runtime** from `nodejs18.x` to `@vercel/node@18`
3. **Configured environment variables** for both development and production
4. **Heart rate data discovery** working with MCP bug workaround
5. **Intelligent query analysis** with Gemini AI integration

## ðŸŽ¯ Current Status

**âœ… Ready for Production Deployment**
- MCP Server: Running on Render
- Frontend: Ready for Vercel
- All integrations: Configured and tested

## ðŸŽ® Available Endpoints

### **Frontend Routes**
- `/` - Main coming soon page
- `/mcp-coach` - Running coach interface
- `/letsjam` - LetsJam functionality

### **API Routes**
- `/api/chat-mcp` - Simple MCP chat
- `/api/chat-mcp-intelligent` - AI-powered intelligent chat
- `/api/mcp-proxy` - MCP server proxy

### **MCP Server Tools**
- `get-recent-activities` - Fetch latest Strava activities
- `get-activity-streams` - Detailed activity data (HR, pace, elevation)
- `get-athlete-profile` - User profile information
- `get-athlete-stats` - Overall statistics

## ðŸ”„ Development vs Production

### **Development Mode**
```bash
# Start local development
npm run dev

# Start local chat server (for testing)
node dev-chat-server.mjs
```
- Uses Vite proxy to `https://strava-mcp-server.onrender.com`
- Local chat server on port 3001 (optional)

### **Production Mode**
- Frontend served from Vercel CDN
- API routes as Vercel serverless functions
- MCP server on Render (always available)

## âœ… Production Checklist

- [x] **MCP Server**: Deployed to Render
- [x] **Environment Variables**: Updated for production URLs
- [x] **API Routes**: Ready for Vercel deployment
- [x] **CORS**: Configured for cross-origin requests
- [x] **Error Handling**: Comprehensive error messages
- [x] **Fallbacks**: Graceful degradation when services unavailable

## ðŸŽ¯ Next Steps

1. **Deploy to Vercel**: `vercel --prod`
2. **Set Environment Variables**: Add production env vars in Vercel dashboard
3. **Test End-to-End**: Verify chat functionality works
4. **Monitor Logs**: Check Vercel and Render logs for issues

## ðŸ”§ Troubleshooting

### **Common Issues**
1. **CORS Errors**: Ensure MCP server has proper CORS headers
2. **API Quota**: Gemini has 50 requests/day on free tier
3. **Cold Starts**: Render apps sleep after 15 minutes of inactivity

### **Debug Commands**
```bash
# Check MCP server health
curl https://strava-mcp-server.onrender.com/health

# Test local proxy
curl http://localhost:8080/api/mcp/health

# Check Vercel logs
vercel logs
```

## ðŸŽ‰ You're Production Ready!

Your intelligent running coach system is now ready for production deployment with:
- âœ… Real Strava data integration
- âœ… AI-powered query analysis 
- âœ… Heart rate and activity analysis
- âœ… Beautiful UI with real-time responses
- âœ… Scalable serverless architecture 
